# 수업 Review


### 실시간 처리의 정의와 비용

- "실시간"의 정의는 사용자와 상황에 따라 다름 - 기술적 실시간과 비즈니스 실시간은 별개
- 데이터 업데이트 빈도는 비용과 직결됨
- 배치 처리(하루 단위)와 실시간 처리(자정 직후) 요구사항은 완전히 다른 접근 필요
- 예시: 자율주행차의 실시간(밀리초 단위)과 우버 배차의 실시간은 다른 개념

### 기술 선택의 의사결정

- 기술을 선택할 때 가장 중요한 것은 유스케이스를 명확히 정하는 것
- "누구를 위해서, 어떤 상황에, 어떻게 필요한 정보로 그 문제를 어떻게 풀겠다"라는 접근이 중요
- 단순히 기술 스펙만 비교하는 것이 아니라, 고객의 문제와 요구사항을 파악하는 것이 핵심
- 기술적으로 배우는 것은 몇 시간이면 되지만, 올바른 의사결정 능력이 더 중요
- 페이스북의 "10일 안에 7명의 친구 추가" 같은 데이터 기반 의사결정 사례

### Hadoop의 한계와 Spark의 등장 배경

- Hadoop은 야후, 페이스북 등에서 대용량 데이터 처리를 위해 개발됨
- 비싼 서버 5대 관리 비용 vs 싸구려 서버 1000대 관리 비용 비교
- Hadoop은 기본적으로 배치 개념이 있을 수밖에 없었고, 실시간 처리에 한계
- HDFS에 데이터를 저장하고 처리하는 것 자체가 엄청난 비용
- MapReduce를 여러 번 돌려야 하는 복잡성과 비용 문제

### Spark가 해결하고자 한 문제

- Fast, Flexible Memory Processing을 통한 Diverse Workflow 지원 (스트리밍, 머신러닝 등)
- 하나의 플랫폼에서 배치와 스트리밍을 모두 처리하고자 함
- 데이터를 매번 복사하고 파이프라인을 다시 만들 필요가 없음
- 다양한 언어 지원(SQL, Python, R, Scala 등)으로 데이터 엔지니어뿐만 아니라 데이터 분석가, 데이터 사이언티스트도 직접 사용 가능

### Spark의 성공 요인

- 기술적으로 가장 빠른 것보다는 사용성과 범용성이 핵심
- 여러 타입의 사용자(SQL 사용자, 머신러닝 엔지니어, 데이터 사이언티스트 등)를 모두 타겟으로 한 전략
- 클라우드 환경에서 in-memory 처리가 더 부담 없이 가능해짐
- 데이터 엔지니어의 업무 부담을 줄이고 각 팀이 직접 처리할 수 있게 함

### Spark 아키텍처 기본 개념

- Spark는 JVM 기반으로 동작
- Driver와 Spark Context라는 핵심 개념 존재
- Driver는 메인 프로세스로 모든 작업의 시작점
- Executor는 애플리케이션 레벨에서 동작하며 컨테이너 안에서 실행
- Driver와 Executor 간 통신이 끊어지면 작업 실패

### Deploy 모드 (배포 옵션)

**Local 모드:** 

- 로컬에서 Spark를 실행하는 모드
- Spark에 내장되어 있는 마스터 사용
- 빠른 테스트나 코드 확인에 적합

**Standalone 클러스터:**  

- Spark 자체의 클러스터 매니저 사용
- Driver가 클라이언트에서 실행되고 Executor를 각 워커에 배포
- Driver와 통신이 유지되어야 함

**YARN 클러스터:** 

- YARN의 Resource Manager를 통해 실행
- Application Master가 먼저 생성되고 그 안에서 작업 관리
- 더 중앙화된 리소스 관리
- HDFS와의 통합: NameNode, DataNode와 연결하여 데이터 처리

### Client vs Cluster Deploy 모드

**Client 모드:**  

- Driver가 클라이언트(외부)에 위치
- 연결이 끊어지면 작업 실패 위험
- 개발 및 테스트 환경에 적합

**Cluster 모드:**  

- Driver가 YARN 컨테이너 안에서 실행
- 연결이 끊어져도 작업 계속 진행 가능
- 검증된 프로덕션 환경에 적합

### 데이터 격리 및 리소스 관리

- 각 Spark 애플리케이션은 독립적인 Executor를 받음
- Spark 애플리케이션 간 데이터는 격리되어 공유 불가
- 컨테이너 레벨에서 리소스 제어