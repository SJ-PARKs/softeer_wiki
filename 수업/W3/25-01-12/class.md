# 수업 Review


## 영상 리뷰
### 학습 태도와 메타인지
- 정직 성실이 매우 중요하다. 
- 모르는 것을 인정하고 배우려는 자세가 필요하다. 
- 자존심 때문에 아는 척하면서 실제로는 모르는 경우가 많다. 
- 원칙과 원리만 이해하면 모든것이 풀린다는 말은 실천이 있어야한다. 


## 빅데이터 시스템
- Unstructured Data가 대량 발생: 어떻게 쓸지 정확히 모르지만 저장해야 함
- 기존 스케일업 방식으로는 비용 문제로 해결 불가
- 클라우드도 없던 시기에 돈을 적게 쓰면서 데이터를 처리해야 하는 과제

### 구글의 해결 과제
- 엄청나게 큰 데이터셋을 저렴한 하드웨어로 안정적으로 저장하고 처리해야 함
- 저렴한 하드웨어는 고장날 수 있으므로 안정성 확보가 필요
- 이렇게 투자를 한번 해서 성공했기 때문에 AI시대에도 투자를 하는 거지 않을까?

## HDFS (Hadoop Distributed File System)

데이터를 분산 저장하는 파일 시스템
- **리던던시(Redundancy)**: 저렴한 하드웨어는 고장날 수 있으므로 데이터를 여러 곳에 복제
- **Write Once, Read Many**: 한 번 쓰고 여러 번 읽는 방식
    - 이 당시에는 CPU, 메모리가 극단적으로 비쌌다
    - 수정하지 않고 계속 읽는 방법으로 복잡도를 낮춤
    - 파일을 고치는 대신 새로 쓰고 인덱스만 바꿔서 새로운 위치를 가리킨다
    - 구글의 웹 로그 수집에 적합한 모델
    - 극단적으로 단순화: 들어오는 데이터를 쓰기만 함, 수정 없음
### 아키텍처
- **Name Node**: 파일시스템 메타데이터 제공 (파일 이름, 위치 정보 등)
    - 데이터 자체는 없고 인덱스만 보유
    - Single point of failure이므로 Secondary Name Node로 백업
- **Data Node**: 실제 데이터를 저장하는 slave node
- **Replication Factor**: 데이터를 몇 곳에 복제할지 결정 (예: 3개)
    - 2개가 고장나도 1개는 살아있어 안정성 보장
- **Rack Awareness**: 같은 랙의 장애를 대비해 다른 랙에도 복제
- **블록 단위 저장**: 파일을 블록으로 나누어 저장


### Data Locality

- **핵심 원칙**: Moving computation is cheaper than moving data
- 데이터를 옮기는 것보다 연산을 데이터가 있는 곳으로 보내는 것이 효율적

  ex) 둡 / 맵리듀스 데이터가 저장된 노드에서 바로 map 실행
- **Data Locality 레벨**:
    - 같은 노드: 가장 효율적
    - 같은 랙: 덜 효율적
    - 다른 랙: 가장 비효율적 (인터랙 데이터 전송)


## YARN (Yet Another Resource Negotiator)

- **핵심 아이디어**: Resource management와 job scheduling/monitoring을 분리
- **Resource Manager (RM)**: 리소스 할당 관리
- **Application Master (AM)**: 애플리케이션별로 생성되어 작업 관리
- **Node Manager**: 각 머신에서 컨테이너 상태 관리

### YARN 작동 방식

1. 클라이언트가 RM에 애플리케이션 제출 
2. RM의 Scheduler가 첫 컨테이너 할당 
3. 해당 컨테이너에서 AM 실행  
4. AM이 RM에 필요한 리소스 요청  
5. AM이 Name Node에 데이터 위치 확인 
6. Data locality를 고려해 컨테이너 할당  
7. AM이 Node Manager에 작업 실행 요청 
8. AM이 작업 모니터링 및 상태 보고  

### RM과 AM의 분리

- **완전한 분리**: RM과 AM은 서로 독립적으로 작동
- RM은 하드웨어 레벨 관리만 담당
- AM은 애플리케이션 내부 로직 관리
- AM이 실패하면 RM이 재시작
- 컨테이너 할당 후에는 AM이 Node Manager와만 통신


## MapReduce

- **핵심 컨셉**: 데이터 병렬처리 패러다임
- **전제조건**:
    - 데이터가 HDFS에 블록 단위로 분산 저장
    - 데이터 패러렐리즘 활용
- **Map 함수**: 각 데이터 블록을 개별적으로 처리
- **Reduce 함수**: Map 결과들을 집계/병합
- **Shuffle**: Map과 Reduce 사이의 데이터 재분배 단계
    - 인터랙 전송이 발생할 수 있어 성능에 영향
- **로컬 디스크 사용**: 중간 데이터는 로컬 디스크에 임시 저장

### MapReduce 예시

- **단어 빈도 계산**: "tree"라는 단어가 몇 번 나오는지 계산
    - 각 블록에서 개별적으로 카운트 (Map)
    - 결과를 합산 (Reduce)
- **감성 분석**:
    - Map: 각 문장을 positive/negative/neutral로 분류
    - Reduce: 각 카테고리별 집계

## 시스템 설계 철학

- **극단적 상황을 위한 극단적 해법**: 데이터는 엄청 많고 컴퓨터는 느림
- **레이어 분리**: 각 레이어가 독립적으로 작동
    - 스토리지 레이어 (HDFS)
    - 리소스 관리 레이어 (YARN)
    - 애플리케이션 레이어 (MapReduce)
- **Fault Tolerance**: 고장이 일어나는 것을 전제로 설계
    - 싸구려 하드웨어는 계속 고장남
    - 리던던시로 안정성 확보
- **단순화**: Write Once 전제로 복잡도 감소


## 아이디어 선정 방법
- Top 3 아이디어 추리기
- 2개씩 짝지어 비교 (Pros & Cons)
- 상대적 장단점 문서화
- Pros & Cons를 시트에 작성하여 제출
- 논의 과정과 컨텍스트를 함께 제출