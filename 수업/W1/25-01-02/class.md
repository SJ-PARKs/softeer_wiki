# 수업 Review


## 회고 관련

- 내 학습 기계를 개선해야 한다.(학습 효율을 높여야 한다.)
- 오늘 단지 에너지가 높아서 한 행동이 아니라 앞으로도 행동이 이어질 수 있게 해야 한다. 그래서 구체적이어야 한다.
- 예를 들어 SQL 지식들을 추가적으로 얻을 수 있었다고 느꼈다면 

    → 매일 아침 스크럼 때, 질문으로 가져갔던 3가지 문제를 적는다.
- 또 다른 예로 

    공식 문서를 보자.→ 5분 동안 공식 문서를 읽어보겠다. 처럼 아주 작은 행동으로 정한다. 본인에 맞는 방법을 찾아보자.
- 회고에 대한 회고도 적자. 회고 메모를 통해 실제로 내 학습 머신이 개선되었는지 확인하자.
- Problem의 해결책을 T에 쓰지 말자.
- 목표가 너무 멀다면 중간 타협점을 찾는다. 예) Current → Unit Test, 중간 단계로 logging과 ETL을 큰 단위로 작성한다.
- 잘 짜자, 신경 쓰자 같은 표현은 X
- 일단 남의 것을 보면서 따라 해본다.



### 우선순위와 학습 행동

- 시간이 없어서 못하는 건 없다. 우선순위를 정해서 해야 한다. 해야 할 목록 중에서 안 해야지라는 의사결정은 보통 잘 안 한다.
- 의사결정을 할 때 urgency를 선택하는 경향이 있다.
- 그러면 importance를 하게 하려면?

    → 학습 기계에 큰 도움을 주는 것은 습관이다. 3분만 해보자처럼 시작하고, entrance를 높아저.



### 미션 제출 (GitHub)

- branch는 다 나뉘어져 있어야 한다.  
  W1M1 → A  
  W1M2 → B  
  W1M3 → C

- 하나의 브랜치에 B, C를 동시에 올리면  
  이게 뭐에요? 하게 된다.

- 그리고 롤백할 때도 문제가 된다.




### 미션 관련

- 시나리오를 짜는 게 좋다고 하셨다. 이야기로 기억하면 된다.
- Jupyter Notebook도 하나의 product로 본다. 이것도 다른 사람이 쓴다. 
- 처음에 team1의 mission1이다 같은 설명을 적는다.
- 고객 관점으로 사고하는 법을 배워야 한다.(고객 마인드)
- M1에서 비어 있다면 어디까지 가야 하는지 써야 한다. 실제로 해봤으면 좋았을 거 같다.
- 추상화 레벨로는 안 된다. 구체적인 사례로 내려와야 한다.


### 데이터 분석에서 질문의 중요성

- 데이터를 가지고 이러이러한 상관관계가 보인다고 말한다.  
  → 아무 의미가 없다.  
  가설을 세우는 것이 좋다. (뭐는 뭐일 것이다).  
  → 분석해 봤을 때 맞다 / 틀리다로   
  안 그러면 내가 이 일을 했으니까 그냥 가치 있다고 주장하게 된다.
- 마력이 연비에 실제로 어떤 영향을 미치는가?  
  이런 질문은 아무짝에 쓸모없다.
    
    → 2개 변수 가지고 한다는 것 자체가 문제..  
  이 질문이 문제가 있어 데이터 분석으로 할 수 있는 게 없다.
- 실제에서는 이게 무슨 문제인가를 잘 정의해야 한다.  
  → 그리고 이 문제를 해결하기 위해 데이터를 구하는 방향.


- 질문을 GPT에 입력하면, 그게 전부인 것처럼 답변을 해준다.  
  하지만 이게 정말 적합한 질문인지는 따로 파악해야 한다.  
  그래야 이 데이터를 어떻게 뽑을지 결정할 수 있다.
- 커뮤니케이션을 잘하기 위해서는 멘토님이었다면,  
  GDP 같은 경우는 빠르게 결과를 먼저 주고 반응을 확인해보는 
  이런 식으로 커뮤니케이션했을 것이다.


### Pandas
- 라이브러리는 원래 더 빠르다. 집중적으로 연구하는 팀이 있으니까.
- pandas를 사용하는 이유는 사고를 덜 쓰고 빠르게 작업할 수 있기 때문이다.




### Extract

- validation을 할지 말지?
- 데이터의 garbage가 너무 많다면,  
  하드에 저장됐다가 메모리에 올라오는 비용이 커서  
  validation을 하기도 한다.
- 하지만 validation이 Transform에 없으면  
  관습에 안 맞는다고 싫어할 수도 있다.
- Extract를 돌리는 machine은  
  빠르게 커졌다가 꺼지는 span 상의 작업이다. (lambda)
- 데이터가 많으면 df.to_json은 비효율적이다.
- Extract File이 있으면 한거고 없으면 안한거고 simple하게

### 코드 리뷰

- Human readable하지 않은 column에 데이터를 임시로 저장하는 행동은 하면 안 된다.
- 각 함수의 Interface 보기좋게 잘하자
- data를 dictionary에 넣어서 처리하지 말자. 돌아가지 않는다.

    -> dataframe은 왜 만들었을까,, 

    loop를 돌려서, apply를 써서 하면 안된다.


- join으로 한다는 것도 연산이 들어간다. 애초에 하나의 frame에 들어가 있으면 더 좋다.



### ETL
- ETL을 완전히 다른 머신으로 생각하자

    E가 가장 적압한 IO dependent한 CPU를 안쓰는 lambda를 한다. 네트워크로
    
    T는 많은 메모리 올려서 하는게 적합


    L은 많은 양의 데이터를 DB에 로딩하는 일. 메모리 거의 필요없다. 

- Data, code, config의 분리
- 반복 사용이 가능해져야한다. 
- 물어봐야한다. 원하는게 간단할 수 있다.
- 데이터 구조에 대한 얘기, versioning에 대한 얘기


### ELT

- DataWarehouse의 성능이 좋아졌다.




주기가 크다면 감당할 수 있을 정도의 컬럼을 생성해놓기
Sql기반 db는 이게 앉호고
column기반 db


### 앞으로 미션 할 때
1. 가지 나열할 수 있는 능력
2. 미션에 뭐가 있었는데 그거 때문에 정했다.
3. 그리고 대안을 선택했다. -> 질문 방법과 연관


- GPT는 그냥 일반적인 대답을 해준다. 
- 특정 가지에 맞춰서 구체적으로 케이스를 생각해야한다. 
- 시나리오 1개라도 쓰자.

    ex) IMF주기는 언제마다 갱신되고 우리는 언제마다 수집할 것이고 

만약 변화에 따라 코드가 일정하다면 
